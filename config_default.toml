# read all hardcoded stuff from here

# THE ASSET DETECTION & LOCALIZATION PIPELINE
[VISUALIZATION]
visualize_trajectory = true
visualize_clusters = true
visualize_cluster_centroids = true
visualize_rays = true
visualize_filtered = true
# midpoint_ray_threshold = 10 # discard needed?

[INITIALIZATION]
reel_frames = "/media/tomas/samQVO_4TB_D/asset-detection-datasets/drtinova_small_u_track/data/reel_undistorted"
work_dir = "/media/tomas/samQVO_4TB_D/assdet-experiments/sml_softmax_new"

[DETECTION] 
command = "" # done by docker just provide command/script to run it

[RAYCASTING] # in: reel + detections   out: rays, midpoints, traj (also serialize to file)
cam_frames_suffix = "jpg"
process_sensors = ["cam0", "cam1", "cam2", "cam3", "cam5"]
frames = 'all' # or specify subset FRAMES = ['2469', '2470', '2471', '2472', '2473']
every_nth = 1
undistort = false
flatten_rays = false
visualize_frames = false
visualize_images = false
debug = false

[PREFILTERING] # distance 
mean_dist_from_cam = 30
max_dist_from_cam = 40
min_score = 0.4


[FEATURES] # extra features by another NN
# TODO: rotate stuff on runtime here
softmax = true
batch_size = 160
# union_method = 'mul' 
debug = true

[FILTERING]
product_feature_max_t = 0.4 # ignore FP detections
ray_epsilon_neighborhood = 1.0

[CLUSTERING]
weighted_centroid = false

# only one of the methods expected here
[CLUSTERING.dbscan]
eps = 1
minPts = 2
semantic_cluster_splitting = true

# OR (sub-dict in python --always means separate implementation ...OR)
# [CLUSTERING.bihierchical]
# t1 = 2 # spatial distance threshold
# t2 = 0.3 # semantic distance threshold
# alpha = 0.5 # in (0,1) -- weight of spatiality 


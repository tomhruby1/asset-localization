# common shared functions
from scipy.spatial.transform import Rotation
from pathlib import Path
from data_structures import Ray 
import numpy as np
import typing as T
import yaml


SENSORS = ['cam0', 'cam1', 'cam2', 'cam3', 'cam5']

def get_midpoint(r1: T.Union[tuple, Ray], r2: T.Union[tuple, Ray], l=False) -> T.Tuple[np.ndarray, float]:
    '''
        Get closest point (intersection hypothesis) for two rays 
        given starting point and direction.
        
        args: 
            - r1: ray or (p1, d1) tuple 
            - r2: ray or (p2, d2) tuple
        
        returns:
            - midpoint
            - ray_dist: length of the closest line segment between r1 and r2
            - l1, l2: lambda distance midpoint to it's respective origin along the ray 
    '''
    if isinstance(r1, Ray):
        p1, d1 = r1.origin, r1.direction
    else:
        p1, d1 = r1
    if isinstance(r2, Ray):
        p2, d2 = r2.origin, r2.direction
    else:
        p2, d2 = r2

    # https://math.stackexchange.com/questions/1414285/shortest-distance-between-vecv-1-and-vecv-2-with-d-frac-vecv-1 
    n  = np.cross(d1,d2)
    n1 = np.cross(d1, n)
    n2 = np.cross(d2, n)
    c1 = p1 + np.dot((p2-p1), n2) / (np.dot(d1, n2)) * d1 #closest p on l1
    c2 = p2 + np.dot((p1-p2), n1) / (np.dot(d2, n1)) * d2 #closest p on l2
    ray_dist = np.linalg.norm(c2-c1)

    if l:
        return (c1 + c2)/2, ray_dist, np.dot((p2-p1), n2) / (np.dot(d1, n2)), np.dot((p1-p2), n1) / (np.dot(d2, n1))
    else:
        return (c1 + c2)/2, ray_dist


def load_calibration(calib_p:T.Union[str, Path], camtype='mx', return_chain=False):
    '''
    Load calibration from calibration chain in YAML. 
    Returns K matrix, vector of distortion coeffs, Transforms and resolution    
    
    returns: 
        Ks, Ds, Ts, resolution
    '''
    
    with open(calib_p, 'r') as f:
        calib_chain = yaml.load(f, Loader=yaml.SafeLoader)

    # indexed by the sensor
    d = {}
    K = {}
    T = {}
    Ts_camchain = get_Ts_from_camchain(calib_chain)
    res = None
    for sensor in SENSORS: 
        fx, fy, cx, cy = calib_chain[sensor]['intrinsics'] 
        d[sensor] = np.asarray(calib_chain[sensor]['distortion_coeffs']) # equidistant distortion model
        K[sensor] = np.array([
            [fx, 0, cx],
            [0, fy, cy],
            [0,  0,  1]
        ])
        if res:
            assert res == calib_chain[sensor]['resolution'] # sensors in one reel have same res
        res = calib_chain[sensor]['resolution']

        camidx = int(sensor[3])
        T[sensor] = Ts_camchain[camidx]

    if return_chain:
        return K, d, T, res, calib_chain
    else:    
        return K, d, T, res

def get_Ts_from_camchain(chain: dict, R0:list=None, t0:list=None) -> list:
    '''
    Extracts Kalibr's camchain results into set of transformation matricies T 

    Params:
        chain: camera chain xml file generated by Kalibr
        R0:    rotation matrix of cam0, non-zero if we would like to adjust ca  m0
               to be properly rotated and aligned on the resulted panoramas
        t0:    translation vector of cam0, non-zero if we need to choose other
               reference point, not cam0 itself
    
    Returns:
        Ts:    list of 4x4 transformation matricies from  cam<N> to cam0
    '''

    if R0 is not None and t0 is not None:
        R0 = Rotation.from_euler('yz', R0, degrees=True).as_matrix()
        t0 = np.array(t0, dtype=float)
    else:
        R0 = np.eye(3)
        t0 = np.asarray([0,0,0])    

    T = np.zeros((4,4))
    T[0:3,0:3] = R0
    T[0:3,3]  = t0    
    
    Ts = [T.copy()]
    camnum = len(chain.keys())
    for cam_id in range(1, camnum):
        cam_name = "cam" + str(cam_id)
        T_cn_cnm1 = np.array(chain[cam_name]['T_cn_cnm1'])
        T = T @ np.linalg.inv(T_cn_cnm1)
        Ts.append(T.copy())

    return Ts

def get_P(R, t, K) -> np.ndarray:
    ''' 
        just build projection matrix given R K matrices + t-vector
        returns 3x4 P matrix
    '''
    P = np.zeros([3,4])
    P[:3,:3] = R
    P[:3, 3] = t
    P = K @ P
    return P


def normalize_homcoords(x: np.ndarray) -> np.ndarray:
    point3d = np.array([x[0]/x[3], x[1]/x[3], x[2]/x[3]]) 
    return point3d


def get_coco_center(bbox, to_cam_center=False, cam_w=3008, cam_h=4096) -> tuple:
    ''' origin_to_center: move origin -- opecv center based i
    '''

    # probably centering necessary -> done by projection P ? 

    centr = [bbox[0]+bbox[2]/2, bbox[1]+bbox[3]/2]
    if to_cam_center:
        camC = (cam_w/2.0, cam_h/2.0)
        centr[0] = centr[0] - camC[0]
        centr[1] = centr[1] - camC[1]

    return centr 
